diff --git a/original_resnet.py b/Resnet.py
index e828ea0..e79f793 100644
--- a/original_resnet.py
+++ b/Resnet.py
@@ -5,6 +5,7 @@ import shutil
 import time
 import warnings
 from enum import Enum
+from torch.utils.tensorboard import SummaryWriter
 
 import torch
 import torch.backends.cudnn as cudnn
@@ -26,8 +27,8 @@ model_names = sorted(name for name in models.__dict__
     and callable(models.__dict__[name]))
 
 parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')
-parser.add_argument('data', metavar='DIR', nargs='?', default='imagenet',
-                    help='path to dataset (default: imagenet)')
+parser.add_argument('data', metavar='DIR', nargs='?', default='tiny-imagenet-200',
+                    help='path to dataset (default: tiny-imagenet-200)') # Reset the data path
 parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',
                     choices=model_names,
                     help='model architecture: ' +
@@ -35,7 +36,7 @@ parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',
                         ' (default: resnet18)')
 parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',
                     help='number of data loading workers (default: 4)')
-parser.add_argument('--epochs', default=90, type=int, metavar='N',
+parser.add_argument('--epochs', default=15, type=int, metavar='N',
                     help='number of total epochs to run')
 parser.add_argument('--start-epoch', default=0, type=int, metavar='N',
                     help='manual epoch number (useful on restarts)')
@@ -80,7 +81,6 @@ parser.add_argument('--dummy', action='store_true', help="use fake data to bench
 
 best_acc1 = 0
 
-
 def main():
     args = parser.parse_args()
 
@@ -121,13 +121,18 @@ def main():
 
 
 def main_worker(gpu, ngpus_per_node, args):
-    global best_acc1
+    """
+    gpu: GPU number used by the current process
+    ngpus_per_node: Number of GPUs per node
+    """
+    global best_acc1 # Track the best accuracy
     args.gpu = gpu
 
-    if args.gpu is not None:
+    if args.gpu is not None: # Determines whether to use the GPU for training
         print("Use GPU: {} for training".format(args.gpu))
+    
 
-    if args.distributed:
+    if args.distributed: # Determine whether to perform distributed training
         if args.dist_url == "env://" and args.rank == -1:
             args.rank = int(os.environ["RANK"])
         if args.multiprocessing_distributed:
@@ -146,6 +151,13 @@ def main_worker(gpu, ngpus_per_node, args):
 
     if not torch.cuda.is_available() and not torch.backends.mps.is_available():
         print('using CPU, this will be slow')
+        # Using tensorboard to draw graph of Resnet18
+        writer = SummaryWriter()
+        fake_img = torch.randn(1, 3, 64, 64)
+        writer.add_graph(model, fake_img)
+        writer.flush()
+        writer.close()
+
     elif args.distributed:
         # For multiprocessing distributed, DistributedDataParallel constructor
         # should always set the single device scope, otherwise,
@@ -188,6 +200,7 @@ def main_worker(gpu, ngpus_per_node, args):
         device = torch.device("mps")
     else:
         device = torch.device("cpu")
+
     # define loss function (criterion), optimizer, and learning rate scheduler
     criterion = nn.CrossEntropyLoss().to(device)
 
@@ -199,6 +212,7 @@ def main_worker(gpu, ngpus_per_node, args):
     scheduler = StepLR(optimizer, step_size=30, gamma=0.1)
     
     # optionally resume from a checkpoint
+    
     if args.resume:
         if os.path.isfile(args.resume):
             print("=> loading checkpoint '{}'".format(args.resume))
@@ -225,8 +239,8 @@ def main_worker(gpu, ngpus_per_node, args):
     # Data loading code
     if args.dummy:
         print("=> Dummy data is used!")
-        train_dataset = datasets.FakeData(1281167, (3, 224, 224), 1000, transforms.ToTensor())
-        val_dataset = datasets.FakeData(50000, (3, 224, 224), 1000, transforms.ToTensor())
+        train_dataset = datasets.FakeData(1281167, (3, 224, 224), 200, transforms.ToTensor())
+        val_dataset = datasets.FakeData(50000, (3, 224, 224), 200, transforms.ToTensor())
     else:
         traindir = os.path.join(args.data, 'train')
         valdir = os.path.join(args.data, 'val')
@@ -236,8 +250,6 @@ def main_worker(gpu, ngpus_per_node, args):
         train_dataset = datasets.ImageFolder(
             traindir,
             transforms.Compose([
-                transforms.RandomResizedCrop(224),
-                transforms.RandomHorizontalFlip(),
                 transforms.ToTensor(),
                 normalize,
             ]))
@@ -245,8 +257,6 @@ def main_worker(gpu, ngpus_per_node, args):
         val_dataset = datasets.ImageFolder(
             valdir,
             transforms.Compose([
-                transforms.Resize(256),
-                transforms.CenterCrop(224),
                 transforms.ToTensor(),
                 normalize,
             ]))
@@ -278,7 +288,7 @@ def main_worker(gpu, ngpus_per_node, args):
         train(train_loader, model, criterion, optimizer, epoch, device, args)
 
         # evaluate on validation set
-        acc1 = validate(val_loader, model, criterion, args)
+        acc1 = validate(val_loader, model, criterion, args, epoch)
         
         scheduler.step()
         
@@ -299,6 +309,7 @@ def main_worker(gpu, ngpus_per_node, args):
 
 
 def train(train_loader, model, criterion, optimizer, epoch, device, args):
+    
     batch_time = AverageMeter('Time', ':6.3f')
     data_time = AverageMeter('Data', ':6.3f')
     losses = AverageMeter('Loss', ':.4e')
@@ -325,8 +336,15 @@ def train(train_loader, model, criterion, optimizer, epoch, device, args):
         output = model(images)
         loss = criterion(output, target)
 
+        writer1.add_scalar("Train loss", loss.item(), i + epoch * len(train_loader))
+        writer1.flush()
+
         # measure accuracy and record loss
         acc1, acc5 = accuracy(output, target, topk=(1, 5))
+        
+        writer2.add_scalar("Train accuracy", acc5[0], i + epoch* len(train_loader)) # acc5
+        writer2.flush()
+        
         losses.update(loss.item(), images.size(0))
         top1.update(acc1[0], images.size(0))
         top5.update(acc5[0], images.size(0))
@@ -343,9 +361,8 @@ def train(train_loader, model, criterion, optimizer, epoch, device, args):
         if i % args.print_freq == 0:
             progress.display(i + 1)
 
-
-def validate(val_loader, model, criterion, args):
-
+def validate(val_loader, model, criterion, args, epoch):
+    
     def run_validate(loader, base_progress=0):
         with torch.no_grad():
             end = time.time()
@@ -363,8 +380,14 @@ def validate(val_loader, model, criterion, args):
                 output = model(images)
                 loss = criterion(output, target)
 
+                writer3.add_scalar("Val loss", loss.item(), i+ epoch * len(loader))
+                writer3.flush()
+
                 # measure accuracy and record loss
                 acc1, acc5 = accuracy(output, target, topk=(1, 5))
+                
+                writer4.add_scalar("Val accuracy", acc5[0], i+ epoch * len(loader))
+                writer4.flush()
                 losses.update(loss.item(), images.size(0))
                 top1.update(acc1[0], images.size(0))
                 top5.update(acc5[0], images.size(0))
@@ -375,7 +398,7 @@ def validate(val_loader, model, criterion, args):
 
                 if i % args.print_freq == 0:
                     progress.display(i + 1)
-
+                
     batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)
     losses = AverageMeter('Loss', ':.4e', Summary.NONE)
     top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)
@@ -400,9 +423,8 @@ def validate(val_loader, model, criterion, args):
             aux_val_dataset, batch_size=args.batch_size, shuffle=False,
             num_workers=args.workers, pin_memory=True)
         run_validate(aux_val_loader, len(val_loader))
-
+ 
     progress.display_summary()
-
     return top1.avg
 
 
@@ -508,4 +530,8 @@ def accuracy(output, target, topk=(1,)):
 
 
 if __name__ == '__main__':
-    main()
+    writer1 = SummaryWriter(log_dir="/output/runs/train_loss")
+    writer2 = SummaryWriter(log_dir="/output/runs/train_acc5")
+    writer3 = SummaryWriter(log_dir="/output/runs/test_loss")
+    writer4 = SummaryWriter(log_dir="/output/runs/test_acc5")
+    main()
\ No newline at end of file
